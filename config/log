21/01/12 11:47:50 - INFO - visualization -   tensorboard file at: logs/single_cell_denoising_transformer_21-01-12-16-47-16_043692
21/01/12 11:47:50 - WARNING - visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality
21/01/12 11:47:50 - WARNING - visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality
21/01/12 11:47:50 - WARNING - visualization -   Cannot watch models when using a TBVisualizer. Configure wandb for this functionality
21/01/12 11:47:50 - INFO - training -   device: cuda n_gpu: 1, distributed_training: False, 16-bits training: True
21/01/12 11:47:50 - INFO - training -   ***** Running training *****
21/01/12 11:47:50 - INFO - training -     Num examples = 3918
21/01/12 11:47:50 - INFO - training -     Batch size = 8
21/01/12 11:47:50 - INFO - training -     Num epochs = 100
21/01/12 11:47:50 - INFO - training -     Num train steps = 48975
21/01/12 11:47:50 - INFO - training -     Num parameters = 1052673
21/01/12 11:48:47 - INFO - training -   [Ep: 0.04][Iter: 20][Time: 57.20s][Loss: 2.3845][Pearson: -0.031823][LR: 3.52e-07]
21/01/12 11:49:01 - INFO - training -   [Ep: 0.08][Iter: 40][Time: 13.91s][Loss: 2.4747][Pearson: -0.029782][LR: 7.04e-07]
21/01/12 11:49:15 - INFO - training -   [Ep: 0.12][Iter: 60][Time: 14.06s][Loss: 2.4536][Pearson: -0.027922][LR: 1.056e-06]
21/01/12 11:49:30 - INFO - training -   [Ep: 0.16][Iter: 80][Time: 14.82s][Loss: 2.2804][Pearson: -0.026488][LR: 1.408e-06]
21/01/12 11:50:22 - INFO - training -   [Ep: 0.20][Iter: 100][Time: 51.71s][Loss: 2.1717][Pearson: -0.026328][LR: 1.76e-06]
21/01/12 11:50:36 - INFO - training -   [Ep: 0.24][Iter: 120][Time: 14.40s][Loss: 2.2045][Pearson: -0.02758][LR: 2.112e-06]
21/01/12 11:50:50 - INFO - training -   [Ep: 0.28][Iter: 140][Time: 13.57s][Loss: 2.2192][Pearson: -0.025263][LR: 2.464e-06]
21/01/12 11:51:04 - INFO - training -   [Ep: 0.32][Iter: 160][Time: 14.08s][Loss: 2.1206][Pearson: -0.022793][LR: 2.816e-06]
21/01/12 11:51:18 - INFO - training -   [Ep: 0.37][Iter: 180][Time: 14.46s][Loss: 1.9699][Pearson: -0.021249][LR: 3.168e-06]
21/01/12 11:52:10 - INFO - training -   [Ep: 0.41][Iter: 200][Time: 51.53s][Loss: 1.9201][Pearson: -0.016196][LR: 3.52e-06]
21/01/12 11:52:25 - INFO - training -   [Ep: 0.45][Iter: 220][Time: 15.46s][Loss: 1.737][Pearson: -0.014462][LR: 3.872e-06]
21/01/12 11:52:39 - INFO - training -   [Ep: 0.49][Iter: 240][Time: 13.27s][Loss: 1.79][Pearson: -0.0073979][LR: 4.224e-06]
21/01/12 11:52:52 - INFO - training -   [Ep: 0.53][Iter: 260][Time: 13.46s][Loss: 1.6235][Pearson: -0.0028045][LR: 4.576e-06]
21/01/12 11:53:06 - INFO - training -   [Ep: 0.57][Iter: 280][Time: 13.86s][Loss: 1.5197][Pearson: -0.00047766][LR: 4.928e-06]
21/01/12 11:53:57 - INFO - training -   [Ep: 0.61][Iter: 300][Time: 51.46s][Loss: 1.325][Pearson: 0.0018284][LR: 5.28e-06]
21/01/12 11:54:10 - INFO - training -   [Ep: 0.65][Iter: 320][Time: 12.87s][Loss: 1.2871][Pearson: 0.0060039][LR: 5.632e-06]
21/01/12 11:54:25 - INFO - training -   [Ep: 0.69][Iter: 340][Time: 14.65s][Loss: 1.1518][Pearson: 0.0082399][LR: 5.984e-06]
21/01/12 11:54:38 - INFO - training -   [Ep: 0.73][Iter: 360][Time: 12.60s][Loss: 1.1767][Pearson: 0.012805][LR: 6.336e-06]
21/01/12 11:54:52 - INFO - training -   [Ep: 0.77][Iter: 380][Time: 14.86s][Loss: 0.99141][Pearson: 0.014799][LR: 6.688e-06]
21/01/12 11:55:40 - INFO - training -   [Ep: 0.81][Iter: 400][Time: 47.29s][Loss: 0.96494][Pearson: 0.01651][LR: 7.04e-06]
21/01/12 11:55:54 - INFO - training -   [Ep: 0.86][Iter: 420][Time: 14.18s][Loss: 0.92727][Pearson: 0.017228][LR: 7.392e-06]
21/01/12 11:56:08 - INFO - training -   [Ep: 0.90][Iter: 440][Time: 14.18s][Loss: 0.86537][Pearson: 0.019763][LR: 7.744e-06]
21/01/12 11:56:21 - INFO - training -   [Ep: 0.94][Iter: 460][Time: 13.41s][Loss: 0.91115][Pearson: 0.022968][LR: 8.096e-06]
21/01/12 11:56:36 - INFO - training -   [Ep: 0.98][Iter: 480][Time: 14.67s][Loss: 0.84094][Pearson: 0.025125][LR: 8.448e-06]
21/01/12 11:56:43 - INFO - training -   Train: [Loss: 1.5857][Pearson: -0.0038146]
21/01/12 12:04:15 - INFO - training -   Evaluation: [Loss: 0.55321][Pearson: 0.0056289]
21/01/12 12:04:15 - INFO - training -   ** ** * Saving trained model ** ** * 
21/01/12 12:04:15 - INFO - training -   Saving model checkpoint to outputs/single_cell_denoising_transformer_21-01-12-16-47-16_043692
21/01/12 12:05:05 - INFO - training -   [Ep: 1.02][Iter: 500][Time: 49.76s][Loss: 0.69879][Pearson: 0.024249][LR: 8.8e-06]
21/01/12 12:05:19 - INFO - training -   [Ep: 1.06][Iter: 520][Time: 14.20s][Loss: 0.7552][Pearson: 0.027309][LR: 9.152e-06]
21/01/12 12:05:32 - INFO - training -   [Ep: 1.10][Iter: 540][Time: 12.68s][Loss: 0.79805][Pearson: 0.030222][LR: 9.504e-06]
21/01/12 12:05:46 - INFO - training -   [Ep: 1.14][Iter: 560][Time: 14.15s][Loss: 0.76108][Pearson: 0.031346][LR: 9.856e-06]
21/01/12 12:06:36 - INFO - training -   [Ep: 1.18][Iter: 580][Time: 49.68s][Loss: 0.74495][Pearson: 0.03424][LR: 1.0208e-05]
21/01/12 12:06:50 - INFO - training -   [Ep: 1.22][Iter: 600][Time: 14.56s][Loss: 0.73348][Pearson: 0.034967][LR: 1.056e-05]
21/01/12 12:07:06 - INFO - training -   [Ep: 1.26][Iter: 620][Time: 15.26s][Loss: 0.70939][Pearson: 0.033515][LR: 1.0912e-05]
21/01/12 12:07:20 - INFO - training -   [Ep: 1.30][Iter: 640][Time: 14.13s][Loss: 0.73405][Pearson: 0.034056][LR: 1.1264e-05]
21/01/12 12:07:33 - INFO - training -   [Ep: 1.34][Iter: 660][Time: 13.62s][Loss: 0.73296][Pearson: 0.034575][LR: 1.1616e-05]
21/01/12 12:08:25 - INFO - training -   [Ep: 1.39][Iter: 680][Time: 51.12s][Loss: 0.74891][Pearson: 0.037581][LR: 1.1968e-05]
21/01/12 12:08:37 - INFO - training -   [Ep: 1.43][Iter: 700][Time: 12.84s][Loss: 0.74139][Pearson: 0.036394][LR: 1.232e-05]
21/01/12 12:08:52 - INFO - training -   [Ep: 1.47][Iter: 720][Time: 14.88s][Loss: 0.73392][Pearson: 0.037759][LR: 1.2672e-05]
21/01/12 12:09:07 - INFO - training -   [Ep: 1.51][Iter: 740][Time: 14.94s][Loss: 0.70468][Pearson: 0.035797][LR: 1.3024e-05]
21/01/12 12:09:21 - INFO - training -   [Ep: 1.55][Iter: 760][Time: 13.45s][Loss: 0.70817][Pearson: 0.036979][LR: 1.3376e-05]
21/01/12 12:10:12 - INFO - training -   [Ep: 1.59][Iter: 780][Time: 51.47s][Loss: 0.69569][Pearson: 0.039304][LR: 1.3728e-05]
21/01/12 12:10:26 - INFO - training -   [Ep: 1.63][Iter: 800][Time: 13.84s][Loss: 0.72064][Pearson: 0.038851][LR: 1.408e-05]
21/01/12 12:10:39 - INFO - training -   [Ep: 1.67][Iter: 820][Time: 13.46s][Loss: 0.73587][Pearson: 0.039654][LR: 1.4432e-05]
21/01/12 12:10:54 - INFO - training -   [Ep: 1.71][Iter: 840][Time: 14.30s][Loss: 0.70248][Pearson: 0.037577][LR: 1.4784e-05]
21/01/12 12:11:08 - INFO - training -   [Ep: 1.75][Iter: 860][Time: 13.98s][Loss: 0.7139][Pearson: 0.038075][LR: 1.5136e-05]
21/01/12 12:11:56 - INFO - training -   [Ep: 1.79][Iter: 880][Time: 48.38s][Loss: 0.6991][Pearson: 0.037172][LR: 1.5488e-05]
21/01/12 12:12:12 - INFO - training -   [Ep: 1.83][Iter: 900][Time: 16.20s][Loss: 0.69226][Pearson: 0.038445][LR: 1.584e-05]
21/01/12 12:12:25 - INFO - training -   [Ep: 1.88][Iter: 920][Time: 12.78s][Loss: 0.69831][Pearson: 0.042565][LR: 1.6192e-05]
21/01/12 12:12:40 - INFO - training -   [Ep: 1.92][Iter: 940][Time: 14.50s][Loss: 0.69053][Pearson: 0.041092][LR: 1.6544e-05]
21/01/12 12:12:54 - INFO - training -   [Ep: 1.96][Iter: 960][Time: 14.17s][Loss: 0.71435][Pearson: 0.042584][LR: 1.6896e-05]
21/01/12 12:13:07 - INFO - training -   [Ep: 2.00][Iter: 980][Time: 13.27s][Loss: 0.71339][Pearson: 0.042799][LR: 1.7248e-05]
21/01/12 12:13:07 - INFO - training -   Train: [Loss: 0.72342][Pearson: 0.036706]
21/01/12 12:20:39 - INFO - training -   Evaluation: [Loss: 0.63331][Pearson: 0.02893]
21/01/12 12:20:39 - INFO - training -   ** ** * Saving trained model ** ** * 
21/01/12 12:20:39 - INFO - training -   Saving model checkpoint to outputs/single_cell_denoising_transformer_21-01-12-16-47-16_043692
21/01/12 12:21:35 - INFO - training -   [Ep: 2.04][Iter: 1000][Time: 56.20s][Loss: 0.70951][Pearson: 0.044455][LR: 1.76e-05]
21/01/12 12:21:50 - INFO - training -   [Ep: 2.08][Iter: 1020][Time: 14.33s][Loss: 0.70496][Pearson: 0.045778][LR: 1.7952e-05]
21/01/12 12:22:03 - INFO - training -   [Ep: 2.12][Iter: 1040][Time: 13.51s][Loss: 0.73865][Pearson: 0.047273][LR: 1.8304e-05]
21/01/12 12:22:18 - INFO - training -   [Ep: 2.16][Iter: 1060][Time: 14.34s][Loss: 0.71926][Pearson: 0.043361][LR: 1.8656e-05]
21/01/12 12:23:09 - INFO - training -   [Ep: 2.20][Iter: 1080][Time: 51.20s][Loss: 0.71378][Pearson: 0.045546][LR: 1.9008e-05]
21/01/12 12:23:23 - INFO - training -   [Ep: 2.24][Iter: 1100][Time: 14.35s][Loss: 0.69475][Pearson: 0.045852][LR: 1.936e-05]
21/01/12 12:23:38 - INFO - training -   [Ep: 2.28][Iter: 1120][Time: 15.04s][Loss: 0.68985][Pearson: 0.046734][LR: 1.9712e-05]
21/01/12 12:23:53 - INFO - training -   [Ep: 2.32][Iter: 1140][Time: 14.56s][Loss: 0.69506][Pearson: 0.048235][LR: 2.0064e-05]
21/01/12 12:24:07 - INFO - training -   [Ep: 2.37][Iter: 1160][Time: 13.85s][Loss: 0.71051][Pearson: 0.050213][LR: 2.0416e-05]
21/01/12 12:24:56 - INFO - training -   [Ep: 2.41][Iter: 1180][Time: 49.96s][Loss: 0.72262][Pearson: 0.050402][LR: 2.0768e-05]
21/01/12 12:25:11 - INFO - training -   [Ep: 2.45][Iter: 1200][Time: 14.75s][Loss: 0.70602][Pearson: 0.049061][LR: 2.112e-05]
21/01/12 12:25:25 - INFO - training -   [Ep: 2.49][Iter: 1220][Time: 13.40s][Loss: 0.7027][Pearson: 0.053407][LR: 2.1472e-05]
21/01/12 12:25:39 - INFO - training -   [Ep: 2.53][Iter: 1240][Time: 14.14s][Loss: 0.70359][Pearson: 0.052721][LR: 2.1824e-05]
21/01/12 12:25:54 - INFO - training -   [Ep: 2.57][Iter: 1260][Time: 14.74s][Loss: 0.68679][Pearson: 0.053669][LR: 2.2176e-05]
21/01/12 12:26:45 - INFO - training -   [Ep: 2.61][Iter: 1280][Time: 51.36s][Loss: 0.69949][Pearson: 0.057567][LR: 2.2528e-05]
21/01/12 12:26:58 - INFO - training -   [Ep: 2.65][Iter: 1300][Time: 13.23s][Loss: 0.72541][Pearson: 0.056781][LR: 2.288e-05]
21/01/12 12:27:14 - INFO - training -   [Ep: 2.69][Iter: 1320][Time: 15.42s][Loss: 0.70493][Pearson: 0.054185][LR: 2.3232e-05]
21/01/12 12:27:27 - INFO - training -   [Ep: 2.73][Iter: 1340][Time: 13.84s][Loss: 0.69742][Pearson: 0.056059][LR: 2.3584e-05]
21/01/12 12:27:42 - INFO - training -   [Ep: 2.77][Iter: 1360][Time: 14.73s][Loss: 0.69416][Pearson: 0.055926][LR: 2.3936e-05]
21/01/12 12:28:28 - INFO - training -   [Ep: 2.81][Iter: 1380][Time: 45.81s][Loss: 0.69815][Pearson: 0.058606][LR: 2.4288e-05]
21/01/12 12:28:42 - INFO - training -   [Ep: 2.86][Iter: 1400][Time: 14.35s][Loss: 0.69585][Pearson: 0.060521][LR: 2.464e-05]
21/01/12 12:28:56 - INFO - training -   [Ep: 2.90][Iter: 1420][Time: 14.11s][Loss: 0.70723][Pearson: 0.063023][LR: 2.4992e-05]
21/01/12 12:29:10 - INFO - training -   [Ep: 2.94][Iter: 1440][Time: 13.98s][Loss: 0.68886][Pearson: 0.060611][LR: 2.5344e-05]
21/01/12 12:29:23 - INFO - training -   [Ep: 2.98][Iter: 1460][Time: 13.11s][Loss: 0.70069][Pearson: 0.064966][LR: 2.5696e-05]
21/01/12 12:29:31 - INFO - training -   Train: [Loss: 0.70576][Pearson: 0.053329]
21/01/12 12:37:03 - INFO - training -   Evaluation: [Loss: 0.61698][Pearson: 0.060226]
21/01/12 12:37:03 - INFO - training -   ** ** * Saving trained model ** ** * 
21/01/12 12:37:04 - INFO - training -   Saving model checkpoint to outputs/single_cell_denoising_transformer_21-01-12-16-47-16_043692
21/01/12 12:37:53 - INFO - training -   [Ep: 3.02][Iter: 1480][Time: 48.73s][Loss: 0.84774][Pearson: 0.069969][LR: 2.6048e-05]
21/01/12 12:38:07 - INFO - training -   [Ep: 3.06][Iter: 1500][Time: 14.70s][Loss: 0.75527][Pearson: 0.0667][LR: 2.64e-05]
21/01/12 12:38:22 - INFO - training -   [Ep: 3.10][Iter: 1520][Time: 14.67s][Loss: 0.7073][Pearson: 0.066712][LR: 2.6752e-05]
21/01/12 12:38:35 - INFO - training -   [Ep: 3.14][Iter: 1540][Time: 12.97s][Loss: 0.72132][Pearson: 0.070113][LR: 2.7104e-05]
21/01/12 12:39:26 - INFO - training -   [Ep: 3.18][Iter: 1560][Time: 51.45s][Loss: 0.69744][Pearson: 0.070147][LR: 2.7456e-05]
21/01/12 12:39:39 - INFO - training -   [Ep: 3.22][Iter: 1580][Time: 12.36s][Loss: 0.7181][Pearson: 0.073291][LR: 2.7808e-05]
21/01/12 12:39:52 - INFO - training -   [Ep: 3.26][Iter: 1600][Time: 13.24s][Loss: 0.72685][Pearson: 0.074684][LR: 2.816e-05]
21/01/12 12:40:08 - INFO - training -   [Ep: 3.30][Iter: 1620][Time: 16.10s][Loss: 0.70218][Pearson: 0.072774][LR: 2.8512e-05]
21/01/12 12:40:23 - INFO - training -   [Ep: 3.34][Iter: 1640][Time: 14.63s][Loss: 0.68297][Pearson: 0.077413][LR: 2.8864e-05]
21/01/12 12:41:14 - INFO - training -   [Ep: 3.39][Iter: 1660][Time: 51.50s][Loss: 0.68965][Pearson: 0.081488][LR: 2.9216e-05]
21/01/12 12:41:29 - INFO - training -   [Ep: 3.43][Iter: 1680][Time: 14.94s][Loss: 0.68321][Pearson: 0.080297][LR: 2.9568e-05]
21/01/12 12:41:42 - INFO - training -   [Ep: 3.47][Iter: 1700][Time: 12.83s][Loss: 0.7019][Pearson: 0.08599][LR: 2.992e-05]
21/01/12 12:41:57 - INFO - training -   [Ep: 3.51][Iter: 1720][Time: 15.53s][Loss: 0.68851][Pearson: 0.086127][LR: 3.0272e-05]
21/01/12 12:42:13 - INFO - training -   [Ep: 3.55][Iter: 1740][Time: 15.31s][Loss: 0.69701][Pearson: 0.087726][LR: 3.0624e-05]
21/01/12 12:43:03 - INFO - training -   [Ep: 3.59][Iter: 1760][Time: 49.74s][Loss: 0.68659][Pearson: 0.090738][LR: 3.0976e-05]
21/01/12 12:43:17 - INFO - training -   [Ep: 3.63][Iter: 1780][Time: 14.46s][Loss: 0.69392][Pearson: 0.093138][LR: 3.1328e-05]
21/01/12 12:43:31 - INFO - training -   [Ep: 3.67][Iter: 1800][Time: 14.40s][Loss: 0.69444][Pearson: 0.092776][LR: 3.168e-05]
21/01/12 12:43:44 - INFO - training -   [Ep: 3.71][Iter: 1820][Time: 12.61s][Loss: 0.69909][Pearson: 0.10147][LR: 3.2032e-05]
21/01/12 12:44:00 - INFO - training -   [Ep: 3.75][Iter: 1840][Time: 15.55s][Loss: 0.68039][Pearson: 0.096089][LR: 3.2384e-05]
21/01/12 12:44:47 - INFO - training -   [Ep: 3.79][Iter: 1860][Time: 47.15s][Loss: 0.69302][Pearson: 0.099551][LR: 3.2736e-05]
21/01/12 12:45:00 - INFO - training -   [Ep: 3.83][Iter: 1880][Time: 13.07s][Loss: 0.69267][Pearson: 0.10557][LR: 3.3088e-05]
21/01/12 12:45:14 - INFO - training -   [Ep: 3.88][Iter: 1900][Time: 14.34s][Loss: 0.68946][Pearson: 0.10529][LR: 3.344e-05]
21/01/12 12:45:28 - INFO - training -   [Ep: 3.92][Iter: 1920][Time: 14.17s][Loss: 0.68452][Pearson: 0.10806][LR: 3.3792e-05]
21/01/12 12:45:42 - INFO - training -   [Ep: 3.96][Iter: 1940][Time: 13.77s][Loss: 0.67751][Pearson: 0.11298][LR: 3.4144e-05]
21/01/12 12:45:57 - INFO - training -   [Ep: 4.00][Iter: 1960][Time: 14.74s][Loss: 0.67798][Pearson: 0.11258][LR: 3.4496e-05]
21/01/12 12:45:57 - INFO - training -   Train: [Loss: 0.69377][Pearson: 0.088254]
21/01/12 12:53:29 - INFO - training -   Evaluation: [Loss: 0.53165][Pearson: 0.11308]
21/01/12 12:53:29 - INFO - training -   ** ** * Saving trained model ** ** * 
21/01/12 12:53:30 - INFO - training -   Saving model checkpoint to outputs/single_cell_denoising_transformer_21-01-12-16-47-16_043692
21/01/12 12:54:25 - INFO - training -   [Ep: 4.04][Iter: 1980][Time: 55.19s][Loss: 0.67531][Pearson: 0.11785][LR: 3.4848e-05]
21/01/12 12:54:39 - INFO - training -   [Ep: 4.08][Iter: 2000][Time: 13.94s][Loss: 0.6847][Pearson: 0.12189][LR: 3.52e-05]
21/01/12 12:54:53 - INFO - training -   [Ep: 4.12][Iter: 2020][Time: 14.51s][Loss: 0.67316][Pearson: 0.12359][LR: 3.5552e-05]
21/01/12 12:55:08 - INFO - training -   [Ep: 4.16][Iter: 2040][Time: 14.37s][Loss: 0.67409][Pearson: 0.12488][LR: 3.5904e-05]
21/01/12 12:55:57 - INFO - training -   [Ep: 4.20][Iter: 2060][Time: 49.77s][Loss: 0.68549][Pearson: 0.1307][LR: 3.6256e-05]
21/01/12 12:56:11 - INFO - training -   [Ep: 4.24][Iter: 2080][Time: 13.49s][Loss: 0.67702][Pearson: 0.13329][LR: 3.6608e-05]
21/01/12 12:56:25 - INFO - training -   [Ep: 4.28][Iter: 2100][Time: 14.20s][Loss: 0.68034][Pearson: 0.13384][LR: 3.696e-05]
21/01/12 12:56:40 - INFO - training -   [Ep: 4.32][Iter: 2120][Time: 14.83s][Loss: 0.66991][Pearson: 0.13541][LR: 3.7312e-05]
21/01/12 12:56:55 - INFO - training -   [Ep: 4.37][Iter: 2140][Time: 15.25s][Loss: 0.66743][Pearson: 0.14085][LR: 3.7664e-05]
21/01/12 12:57:46 - INFO - training -   [Ep: 4.41][Iter: 2160][Time: 50.93s][Loss: 0.66346][Pearson: 0.14523][LR: 3.8016e-05]
21/01/12 12:58:00 - INFO - training -   [Ep: 4.45][Iter: 2180][Time: 14.11s][Loss: 0.66026][Pearson: 0.14253][LR: 3.8368e-05]
21/01/12 12:58:15 - INFO - training -   [Ep: 4.49][Iter: 2200][Time: 15.20s][Loss: 0.65395][Pearson: 0.14204][LR: 3.872e-05]
21/01/12 12:58:31 - INFO - training -   [Ep: 4.53][Iter: 2220][Time: 15.08s][Loss: 0.65662][Pearson: 0.14727][LR: 3.9072e-05]
21/01/12 12:58:45 - INFO - training -   [Ep: 4.57][Iter: 2240][Time: 14.38s][Loss: 0.67119][Pearson: 0.15267][LR: 3.9424e-05]
21/01/12 12:59:35 - INFO - training -   [Ep: 4.61][Iter: 2260][Time: 49.79s][Loss: 0.67247][Pearson: 0.15678][LR: 3.9776e-05]
21/01/12 12:59:49 - INFO - training -   [Ep: 4.65][Iter: 2280][Time: 14.16s][Loss: 0.65782][Pearson: 0.15877][LR: 4.0128e-05]
21/01/12 13:00:04 - INFO - training -   [Ep: 4.69][Iter: 2300][Time: 14.97s][Loss: 0.65046][Pearson: 0.15867][LR: 4.048e-05]
21/01/12 13:00:17 - INFO - training -   [Ep: 4.73][Iter: 2320][Time: 13.38s][Loss: 0.65492][Pearson: 0.16604][LR: 4.0832e-05]
21/01/12 13:00:31 - INFO - training -   [Ep: 4.77][Iter: 2340][Time: 13.73s][Loss: 0.66361][Pearson: 0.16813][LR: 4.1184e-05]
21/01/12 13:01:19 - INFO - training -   [Ep: 4.81][Iter: 2360][Time: 47.65s][Loss: 0.65283][Pearson: 0.16928][LR: 4.1536e-05]
21/01/12 13:01:34 - INFO - training -   [Ep: 4.86][Iter: 2380][Time: 15.59s][Loss: 0.64994][Pearson: 0.17234][LR: 4.1888e-05]
21/01/12 13:01:48 - INFO - training -   [Ep: 4.90][Iter: 2400][Time: 13.54s][Loss: 0.64576][Pearson: 0.17529][LR: 4.224e-05]
21/01/12 13:02:02 - INFO - training -   [Ep: 4.94][Iter: 2420][Time: 14.43s][Loss: 0.6434][Pearson: 0.18162][LR: 4.2592e-05]
21/01/12 13:02:16 - INFO - training -   [Ep: 4.98][Iter: 2440][Time: 13.37s][Loss: 0.64413][Pearson: 0.18846][LR: 4.2944e-05]
21/01/12 13:02:23 - INFO - training -   Train: [Loss: 0.66411][Pearson: 0.15161]
21/01/12 13:09:54 - INFO - training -   Evaluation: [Loss: 0.52552][Pearson: 0.1666]
21/01/12 13:09:54 - INFO - training -   ** ** * Saving trained model ** ** * 
21/01/12 13:09:54 - INFO - training -   Saving model checkpoint to outputs/single_cell_denoising_transformer_21-01-12-16-47-16_043692
21/01/12 13:10:43 - INFO - training -   [Ep: 5.02][Iter: 2460][Time: 49.06s][Loss: 0.64258][Pearson: 0.18043][LR: 4.3296e-05]
21/01/12 13:10:58 - INFO - training -   [Ep: 5.06][Iter: 2480][Time: 14.35s][Loss: 0.63844][Pearson: 0.19224][LR: 4.3648e-05]
21/01/12 13:11:12 - INFO - training -   [Ep: 5.10][Iter: 2500][Time: 14.33s][Loss: 0.6376][Pearson: 0.19439][LR: 4.4e-05]
21/01/12 13:11:26 - INFO - training -   [Ep: 5.14][Iter: 2520][Time: 14.31s][Loss: 0.64986][Pearson: 0.20207][LR: 4.4352e-05]
21/01/12 13:12:17 - INFO - training -   [Ep: 5.18][Iter: 2540][Time: 50.61s][Loss: 0.64977][Pearson: 0.20801][LR: 4.4704e-05]
21/01/12 13:12:31 - INFO - training -   [Ep: 5.22][Iter: 2560][Time: 13.81s][Loss: 0.65308][Pearson: 0.20668][LR: 4.5056e-05]
21/01/12 13:12:46 - INFO - training -   [Ep: 5.26][Iter: 2580][Time: 15.17s][Loss: 0.64067][Pearson: 0.20984][LR: 4.5408e-05]
21/01/12 13:13:00 - INFO - training -   [Ep: 5.30][Iter: 2600][Time: 14.33s][Loss: 0.63607][Pearson: 0.21366][LR: 4.576e-05]
21/01/12 13:13:15 - INFO - training -   [Ep: 5.34][Iter: 2620][Time: 14.63s][Loss: 0.64125][Pearson: 0.21802][LR: 4.6112e-05]
21/01/12 13:14:05 - INFO - training -   [Ep: 5.39][Iter: 2640][Time: 49.63s][Loss: 0.63445][Pearson: 0.22765][LR: 4.6464e-05]
21/01/12 13:14:19 - INFO - training -   [Ep: 5.43][Iter: 2660][Time: 14.18s][Loss: 0.63101][Pearson: 0.22811][LR: 4.6816e-05]
21/01/12 13:14:34 - INFO - training -   [Ep: 5.47][Iter: 2680][Time: 14.91s][Loss: 0.632][Pearson: 0.23021][LR: 4.7168e-05]
21/01/12 13:14:47 - INFO - training -   [Ep: 5.51][Iter: 2700][Time: 13.67s][Loss: 0.628][Pearson: 0.23568][LR: 4.752e-05]
21/01/12 13:15:02 - INFO - training -   [Ep: 5.55][Iter: 2720][Time: 14.34s][Loss: 0.62136][Pearson: 0.23809][LR: 4.7872e-05]
21/01/12 13:15:53 - INFO - training -   [Ep: 5.59][Iter: 2740][Time: 51.19s][Loss: 0.61949][Pearson: 0.24396][LR: 4.8224e-05]
21/01/12 13:16:07 - INFO - training -   [Ep: 5.63][Iter: 2760][Time: 14.03s][Loss: 0.62467][Pearson: 0.24916][LR: 4.8576e-05]
21/01/12 13:16:22 - INFO - training -   [Ep: 5.67][Iter: 2780][Time: 15.17s][Loss: 0.6217][Pearson: 0.2492][LR: 4.8928e-05]
21/01/12 13:16:36 - INFO - training -   [Ep: 5.71][Iter: 2800][Time: 13.47s][Loss: 0.62375][Pearson: 0.25838][LR: 4.928e-05]
21/01/12 13:16:51 - INFO - training -   [Ep: 5.75][Iter: 2820][Time: 15.42s][Loss: 0.6232][Pearson: 0.25604][LR: 4.9632e-05]
21/01/12 13:17:37 - INFO - training -   [Ep: 5.79][Iter: 2840][Time: 45.85s][Loss: 0.62268][Pearson: 0.2688][LR: 4.9984e-05]
21/01/12 13:17:50 - INFO - training -   [Ep: 5.83][Iter: 2860][Time: 13.40s][Loss: 0.61558][Pearson: 0.2743][LR: 5.0336e-05]
21/01/12 13:18:04 - INFO - training -   [Ep: 5.88][Iter: 2880][Time: 14.29s][Loss: 0.61838][Pearson: 0.27252][LR: 5.0688e-05]
21/01/12 13:18:19 - INFO - training -   [Ep: 5.92][Iter: 2900][Time: 14.77s][Loss: 0.62464][Pearson: 0.27618][LR: 5.104e-05]
21/01/12 13:18:34 - INFO - training -   [Ep: 5.96][Iter: 2920][Time: 14.89s][Loss: 0.61541][Pearson: 0.28102][LR: 5.1392e-05]
21/01/12 13:18:48 - INFO - training -   [Ep: 6.00][Iter: 2940][Time: 14.20s][Loss: 0.61871][Pearson: 0.28511][LR: 5.1744e-05]
21/01/12 13:18:49 - INFO - training -   Train: [Loss: 0.63019][Pearson: 0.23935]
21/01/12 13:26:20 - INFO - training -   Evaluation: [Loss: 0.47174][Pearson: 0.27483]
21/01/12 13:26:20 - INFO - training -   ** ** * Saving trained model ** ** * 
21/01/12 13:26:22 - INFO - training -   Saving model checkpoint to outputs/single_cell_denoising_transformer_21-01-12-16-47-16_043692
21/01/12 13:27:18 - INFO - training -   [Ep: 6.04][Iter: 2960][Time: 55.87s][Loss: 0.60639][Pearson: 0.30599][LR: 5.2096e-05]
21/01/12 13:27:34 - INFO - training -   [Ep: 6.08][Iter: 2980][Time: 15.69s][Loss: 0.60595][Pearson: 0.29862][LR: 5.2448e-05]
21/01/12 13:27:49 - INFO - training -   [Ep: 6.12][Iter: 3000][Time: 14.84s][Loss: 0.60648][Pearson: 0.30043][LR: 5.28e-05]
21/01/12 13:28:01 - INFO - training -   [Ep: 6.16][Iter: 3020][Time: 12.83s][Loss: 0.60667][Pearson: 0.30931][LR: 5.3152e-05]
21/01/12 13:28:53 - INFO - training -   [Ep: 6.20][Iter: 3040][Time: 51.22s][Loss: 0.6057][Pearson: 0.31197][LR: 5.3504e-05]
21/01/12 13:29:08 - INFO - training -   [Ep: 6.24][Iter: 3060][Time: 15.66s][Loss: 0.6022][Pearson: 0.31153][LR: 5.3856e-05]
21/01/12 13:29:22 - INFO - training -   [Ep: 6.28][Iter: 3080][Time: 13.83s][Loss: 0.60082][Pearson: 0.31733][LR: 5.4208e-05]
21/01/12 13:29:36 - INFO - training -   [Ep: 6.32][Iter: 3100][Time: 13.89s][Loss: 0.59832][Pearson: 0.32428][LR: 5.456e-05]
21/01/12 13:29:50 - INFO - training -   [Ep: 6.37][Iter: 3120][Time: 13.75s][Loss: 0.59918][Pearson: 0.3279][LR: 5.4912e-05]
21/01/12 13:30:42 - INFO - training -   [Ep: 6.41][Iter: 3140][Time: 52.08s][Loss: 0.59635][Pearson: 0.33073][LR: 5.5264e-05]
21/01/12 13:30:58 - INFO - training -   [Ep: 6.45][Iter: 3160][Time: 16.11s][Loss: 0.59246][Pearson: 0.32991][LR: 5.5616e-05]
21/01/12 13:31:12 - INFO - training -   [Ep: 6.49][Iter: 3180][Time: 14.11s][Loss: 0.59446][Pearson: 0.33532][LR: 5.5968e-05]
21/01/12 13:31:26 - INFO - training -   [Ep: 6.53][Iter: 3200][Time: 14.04s][Loss: 0.59124][Pearson: 0.3442][LR: 5.632e-05]
21/01/12 13:31:39 - INFO - training -   [Ep: 6.57][Iter: 3220][Time: 13.32s][Loss: 0.58769][Pearson: 0.34913][LR: 5.6672e-05]
21/01/12 13:32:32 - INFO - training -   [Ep: 6.61][Iter: 3240][Time: 52.17s][Loss: 0.58893][Pearson: 0.34549][LR: 5.7024e-05]
21/01/12 13:32:46 - INFO - training -   [Ep: 6.65][Iter: 3260][Time: 14.78s][Loss: 0.59403][Pearson: 0.35089][LR: 5.7376e-05]
21/01/12 13:33:01 - INFO - training -   [Ep: 6.69][Iter: 3280][Time: 14.84s][Loss: 0.59146][Pearson: 0.35728][LR: 5.7728e-05]
21/01/12 13:33:16 - INFO - training -   [Ep: 6.73][Iter: 3300][Time: 14.90s][Loss: 0.58628][Pearson: 0.3611][LR: 5.808e-05]
21/01/12 13:33:30 - INFO - training -   [Ep: 6.77][Iter: 3320][Time: 14.04s][Loss: 0.58344][Pearson: 0.36847][LR: 5.8432e-05]
21/01/12 13:34:15 - INFO - training -   [Ep: 6.81][Iter: 3340][Time: 45.03s][Loss: 0.58342][Pearson: 0.37937][LR: 5.8784e-05]
21/01/12 13:34:28 - INFO - training -   [Ep: 6.86][Iter: 3360][Time: 13.13s][Loss: 0.57407][Pearson: 0.38117][LR: 5.9136e-05]
21/01/12 13:34:42 - INFO - training -   [Ep: 6.90][Iter: 3380][Time: 14.01s][Loss: 0.57539][Pearson: 0.38004][LR: 5.9488e-05]
21/01/12 13:34:57 - INFO - training -   [Ep: 6.94][Iter: 3400][Time: 15.13s][Loss: 0.57516][Pearson: 0.3797][LR: 5.984e-05]
21/01/12 13:35:11 - INFO - training -   [Ep: 6.98][Iter: 3420][Time: 13.99s][Loss: 0.57118][Pearson: 0.38635][LR: 6.0192e-05]
21/01/12 13:35:18 - INFO - training -   Train: [Loss: 0.59117][Pearson: 0.343]
21/01/12 13:42:50 - INFO - training -   Evaluation: [Loss: 0.41371][Pearson: 0.39505]
21/01/12 13:42:50 - INFO - training -   ** ** * Saving trained model ** ** * 
21/01/12 13:42:51 - INFO - training -   Saving model checkpoint to outputs/single_cell_denoising_transformer_21-01-12-16-47-16_043692
21/01/12 13:43:39 - INFO - training -   [Ep: 7.02][Iter: 3440][Time: 48.77s][Loss: 0.56361][Pearson: 0.38759][LR: 6.0544e-05]
21/01/12 13:43:53 - INFO - training -   [Ep: 7.06][Iter: 3460][Time: 14.16s][Loss: 0.5632][Pearson: 0.39719][LR: 6.0896e-05]
21/01/12 13:44:07 - INFO - training -   [Ep: 7.10][Iter: 3480][Time: 13.42s][Loss: 0.56504][Pearson: 0.40701][LR: 6.1248e-05]
21/01/12 13:44:22 - INFO - training -   [Ep: 7.14][Iter: 3500][Time: 14.91s][Loss: 0.56322][Pearson: 0.4079][LR: 6.16e-05]
21/01/12 13:45:12 - INFO - training -   [Ep: 7.18][Iter: 3520][Time: 50.54s][Loss: 0.55819][Pearson: 0.41294][LR: 6.1952e-05]
21/01/12 13:45:26 - INFO - training -   [Ep: 7.22][Iter: 3540][Time: 13.38s][Loss: 0.56069][Pearson: 0.41733][LR: 6.2304e-05]
21/01/12 13:45:40 - INFO - training -   [Ep: 7.26][Iter: 3560][Time: 13.94s][Loss: 0.55613][Pearson: 0.42436][LR: 6.2656e-05]
21/01/12 13:45:54 - INFO - training -   [Ep: 7.30][Iter: 3580][Time: 14.86s][Loss: 0.55373][Pearson: 0.42789][LR: 6.3008e-05]
21/01/12 13:46:09 - INFO - training -   [Ep: 7.34][Iter: 3600][Time: 14.66s][Loss: 0.55172][Pearson: 0.43531][LR: 6.336e-05]
21/01/12 13:47:00 - INFO - training -   [Ep: 7.39][Iter: 3620][Time: 50.36s][Loss: 0.54891][Pearson: 0.43919][LR: 6.3712e-05]
21/01/12 13:47:14 - INFO - training -   [Ep: 7.43][Iter: 3640][Time: 14.94s][Loss: 0.54767][Pearson: 0.44411][LR: 6.4064e-05]
21/01/12 13:47:29 - INFO - training -   [Ep: 7.47][Iter: 3660][Time: 14.61s][Loss: 0.54397][Pearson: 0.45094][LR: 6.4416e-05]
21/01/12 13:47:42 - INFO - training -   [Ep: 7.51][Iter: 3680][Time: 13.35s][Loss: 0.54039][Pearson: 0.45683][LR: 6.4768e-05]
21/01/12 13:47:56 - INFO - training -   [Ep: 7.55][Iter: 3700][Time: 13.21s][Loss: 0.53839][Pearson: 0.46643][LR: 6.512e-05]
21/01/12 13:48:47 - INFO - training -   [Ep: 7.59][Iter: 3720][Time: 51.48s][Loss: 0.5322][Pearson: 0.46774][LR: 6.5472e-05]
21/01/12 13:49:02 - INFO - training -   [Ep: 7.63][Iter: 3740][Time: 15.37s][Loss: 0.52693][Pearson: 0.46974][LR: 6.5824e-05]
21/01/12 13:49:16 - INFO - training -   [Ep: 7.67][Iter: 3760][Time: 13.53s][Loss: 0.5198][Pearson: 0.47994][LR: 6.6176e-05]
21/01/12 13:49:30 - INFO - training -   [Ep: 7.71][Iter: 3780][Time: 13.92s][Loss: 0.52089][Pearson: 0.49151][LR: 6.6528e-05]
21/01/12 13:49:43 - INFO - training -   [Ep: 7.75][Iter: 3800][Time: 12.79s][Loss: 0.51125][Pearson: 0.49812][LR: 6.688e-05]
21/01/12 13:50:31 - INFO - training -   [Ep: 7.79][Iter: 3820][Time: 48.06s][Loss: 0.51507][Pearson: 0.50295][LR: 6.7232e-05]
21/01/12 13:50:45 - INFO - training -   [Ep: 7.83][Iter: 3840][Time: 14.41s][Loss: 0.509][Pearson: 0.50939][LR: 6.7584e-05]
21/01/12 13:51:03 - INFO - training -   [Ep: 7.88][Iter: 3860][Time: 17.45s][Loss: 0.50243][Pearson: 0.51439][LR: 6.7936e-05]
21/01/12 13:51:17 - INFO - training -   [Ep: 7.92][Iter: 3880][Time: 14.18s][Loss: 0.50187][Pearson: 0.52269][LR: 6.8288e-05]
21/01/12 13:51:32 - INFO - training -   [Ep: 7.96][Iter: 3900][Time: 15.14s][Loss: 0.49719][Pearson: 0.53047][LR: 6.864e-05]
21/01/12 13:51:46 - INFO - training -   [Ep: 8.00][Iter: 3920][Time: 13.57s][Loss: 0.48744][Pearson: 0.53836][LR: 6.8992e-05]
21/01/12 13:51:46 - INFO - training -   Train: [Loss: 0.53376][Pearson: 0.4647]
21/01/12 13:59:18 - INFO - training -   Evaluation: [Loss: 0.34108][Pearson: 0.54414]
21/01/12 13:59:18 - INFO - training -   ** ** * Saving trained model ** ** * 
21/01/12 13:59:18 - INFO - training -   Saving model checkpoint to outputs/single_cell_denoising_transformer_21-01-12-16-47-16_043692
21/01/12 14:00:14 - INFO - training -   [Ep: 8.04][Iter: 3940][Time: 55.90s][Loss: 0.4803][Pearson: 0.55069][LR: 6.9344e-05]
21/01/12 14:00:28 - INFO - training -   [Ep: 8.08][Iter: 3960][Time: 13.76s][Loss: 0.47554][Pearson: 0.55499][LR: 6.9696e-05]
21/01/12 14:00:42 - INFO - training -   [Ep: 8.12][Iter: 3980][Time: 14.27s][Loss: 0.47124][Pearson: 0.56376][LR: 7.0048e-05]
21/01/12 14:00:56 - INFO - training -   [Ep: 8.16][Iter: 4000][Time: 14.01s][Loss: 0.46598][Pearson: 0.56926][LR: 7.04e-05]
21/01/12 14:01:48 - INFO - training -   [Ep: 8.20][Iter: 4020][Time: 51.87s][Loss: 0.4633][Pearson: 0.57634][LR: 7.0752e-05]
21/01/12 14:02:03 - INFO - training -   [Ep: 8.24][Iter: 4040][Time: 15.23s][Loss: 0.45631][Pearson: 0.58424][LR: 7.1104e-05]
21/01/12 14:02:18 - INFO - training -   [Ep: 8.28][Iter: 4060][Time: 14.89s][Loss: 0.44692][Pearson: 0.5904][LR: 7.1456e-05]
21/01/12 14:02:33 - INFO - training -   [Ep: 8.32][Iter: 4080][Time: 14.97s][Loss: 0.44235][Pearson: 0.59859][LR: 7.1808e-05]
21/01/12 14:02:47 - INFO - training -   [Ep: 8.37][Iter: 4100][Time: 13.72s][Loss: 0.43167][Pearson: 0.60815][LR: 7.216e-05]
21/01/12 14:03:36 - INFO - training -   [Ep: 8.41][Iter: 4120][Time: 49.77s][Loss: 0.42018][Pearson: 0.61313][LR: 7.2512e-05]
21/01/12 14:03:52 - INFO - training -   [Ep: 8.45][Iter: 4140][Time: 15.64s][Loss: 0.42328][Pearson: 0.61988][LR: 7.2864e-05]
21/01/12 14:04:05 - INFO - training -   [Ep: 8.49][Iter: 4160][Time: 12.70s][Loss: 0.41087][Pearson: 0.63452][LR: 7.3216e-05]
21/01/12 14:04:19 - INFO - training -   [Ep: 8.53][Iter: 4180][Time: 13.81s][Loss: 0.40982][Pearson: 0.64078][LR: 7.3568e-05]
21/01/12 14:04:32 - INFO - training -   [Ep: 8.57][Iter: 4200][Time: 13.65s][Loss: 0.40393][Pearson: 0.64543][LR: 7.392e-05]
21/01/12 14:05:24 - INFO - training -   [Ep: 8.61][Iter: 4220][Time: 51.70s][Loss: 0.39892][Pearson: 0.65052][LR: 7.4272e-05]
21/01/12 14:05:39 - INFO - training -   [Ep: 8.65][Iter: 4240][Time: 14.70s][Loss: 0.38961][Pearson: 0.66149][LR: 7.4624e-05]
21/01/12 14:05:53 - INFO - training -   [Ep: 8.69][Iter: 4260][Time: 14.75s][Loss: 0.3852][Pearson: 0.66564][LR: 7.4976e-05]
21/01/12 14:06:09 - INFO - training -   [Ep: 8.73][Iter: 4280][Time: 15.87s][Loss: 0.38005][Pearson: 0.67102][LR: 7.5328e-05]
21/01/12 14:06:21 - INFO - training -   [Ep: 8.77][Iter: 4300][Time: 11.95s][Loss: 0.36146][Pearson: 0.6838][LR: 7.568e-05]
21/01/12 14:07:08 - INFO - training -   [Ep: 8.81][Iter: 4320][Time: 47.32s][Loss: 0.35795][Pearson: 0.68588][LR: 7.6032e-05]
21/01/12 14:07:23 - INFO - training -   [Ep: 8.86][Iter: 4340][Time: 14.42s][Loss: 0.35483][Pearson: 0.69204][LR: 7.6384e-05]
21/01/12 14:07:37 - INFO - training -   [Ep: 8.90][Iter: 4360][Time: 14.28s][Loss: 0.34919][Pearson: 0.69932][LR: 7.6736e-05]
21/01/12 14:07:52 - INFO - training -   [Ep: 8.94][Iter: 4380][Time: 14.65s][Loss: 0.34327][Pearson: 0.70756][LR: 7.7088e-05]
21/01/12 14:08:06 - INFO - training -   [Ep: 8.98][Iter: 4400][Time: 14.34s][Loss: 0.33836][Pearson: 0.70976][LR: 7.744e-05]
21/01/12 14:08:13 - INFO - training -   Train: [Loss: 0.40609][Pearson: 0.63736]
21/01/12 14:15:45 - INFO - training -   Evaluation: [Loss: 0.29008][Pearson: 0.68397]
21/01/12 14:15:45 - INFO - training -   ** ** * Saving trained model ** ** * 
21/01/12 14:15:45 - INFO - training -   Saving model checkpoint to outputs/single_cell_denoising_transformer_21-01-12-16-47-16_043692
21/01/12 14:16:34 - INFO - training -   [Ep: 9.02][Iter: 4420][Time: 48.19s][Loss: 0.33253][Pearson: 0.7248][LR: 7.7792e-05]
21/01/12 14:16:47 - INFO - training -   [Ep: 9.06][Iter: 4440][Time: 13.82s][Loss: 0.32691][Pearson: 0.72628][LR: 7.8144e-05]
21/01/12 14:17:03 - INFO - training -   [Ep: 9.10][Iter: 4460][Time: 15.36s][Loss: 0.32644][Pearson: 0.72287][LR: 7.8496e-05]
21/01/12 14:17:17 - INFO - training -   [Ep: 9.14][Iter: 4480][Time: 13.94s][Loss: 0.31661][Pearson: 0.72595][LR: 7.8848e-05]
21/01/12 14:18:07 - INFO - training -   [Ep: 9.18][Iter: 4500][Time: 50.26s][Loss: 0.31085][Pearson: 0.73402][LR: 7.92e-05]
21/01/12 14:18:21 - INFO - training -   [Ep: 9.22][Iter: 4520][Time: 14.34s][Loss: 0.30877][Pearson: 0.74026][LR: 7.9552e-05]
21/01/12 14:18:36 - INFO - training -   [Ep: 9.26][Iter: 4540][Time: 15.19s][Loss: 0.30796][Pearson: 0.74003][LR: 7.9904e-05]
21/01/12 14:18:51 - INFO - training -   [Ep: 9.30][Iter: 4560][Time: 14.12s][Loss: 0.30203][Pearson: 0.74403][LR: 8.0256e-05]
21/01/12 14:19:05 - INFO - training -   [Ep: 9.34][Iter: 4580][Time: 13.96s][Loss: 0.29274][Pearson: 0.75165][LR: 8.0608e-05]
21/01/12 14:19:56 - INFO - training -   [Ep: 9.39][Iter: 4600][Time: 51.54s][Loss: 0.29171][Pearson: 0.75305][LR: 8.096e-05]
21/01/12 14:20:09 - INFO - training -   [Ep: 9.43][Iter: 4620][Time: 13.14s][Loss: 0.28347][Pearson: 0.76359][LR: 8.1312e-05]
21/01/12 14:20:24 - INFO - training -   [Ep: 9.47][Iter: 4640][Time: 14.81s][Loss: 0.28321][Pearson: 0.76099][LR: 8.1664e-05]
21/01/12 14:20:37 - INFO - training -   [Ep: 9.51][Iter: 4660][Time: 12.95s][Loss: 0.27521][Pearson: 0.76776][LR: 8.2016e-05]
21/01/12 14:20:50 - INFO - training -   [Ep: 9.55][Iter: 4680][Time: 12.99s][Loss: 0.27568][Pearson: 0.76891][LR: 8.2368e-05]
21/01/12 14:21:42 - INFO - training -   [Ep: 9.59][Iter: 4700][Time: 51.99s][Loss: 0.27667][Pearson: 0.76759][LR: 8.272e-05]
21/01/12 14:21:57 - INFO - training -   [Ep: 9.63][Iter: 4720][Time: 15.11s][Loss: 0.27428][Pearson: 0.76986][LR: 8.3072e-05]
21/01/12 14:22:11 - INFO - training -   [Ep: 9.67][Iter: 4740][Time: 13.50s][Loss: 0.27466][Pearson: 0.77072][LR: 8.3424e-05]
21/01/12 14:22:24 - INFO - training -   [Ep: 9.71][Iter: 4760][Time: 13.89s][Loss: 0.26639][Pearson: 0.77778][LR: 8.3776e-05]
21/01/12 14:22:38 - INFO - training -   [Ep: 9.75][Iter: 4780][Time: 14.01s][Loss: 0.26273][Pearson: 0.7808][LR: 8.4128e-05]
21/01/12 14:23:24 - INFO - training -   [Ep: 9.79][Iter: 4800][Time: 45.91s][Loss: 0.26248][Pearson: 0.77904][LR: 8.448e-05]
21/01/12 14:23:39 - INFO - training -   [Ep: 9.83][Iter: 4820][Time: 14.70s][Loss: 0.26356][Pearson: 0.77822][LR: 8.4832e-05]
21/01/12 14:23:53 - INFO - training -   [Ep: 9.88][Iter: 4840][Time: 13.51s][Loss: 0.25678][Pearson: 0.78307][LR: 8.5184e-05]
21/01/12 14:24:06 - INFO - training -   [Ep: 9.92][Iter: 4860][Time: 13.06s][Loss: 0.25421][Pearson: 0.78725][LR: 8.5536e-05]
21/01/12 14:24:21 - INFO - training -   [Ep: 9.96][Iter: 4880][Time: 15.19s][Loss: 0.25548][Pearson: 0.78738][LR: 8.5888e-05]
21/01/12 14:24:36 - INFO - training -   [Ep: 10.00][Iter: 4900][Time: 15.03s][Loss: 0.25217][Pearson: 0.79026][LR: 8.624e-05]
21/01/12 14:24:36 - INFO - training -   Train: [Loss: 0.28276][Pearson: 0.76163]
21/01/12 14:32:08 - INFO - training -   Evaluation: [Loss: 0.36766][Pearson: 0.72799]
21/01/12 14:32:08 - INFO - training -   ** ** * Saving trained model ** ** * 
21/01/12 14:32:08 - INFO - training -   Saving model checkpoint to outputs/single_cell_denoising_transformer_21-01-12-16-47-16_043692
21/01/12 14:33:06 - INFO - training -   [Ep: 10.04][Iter: 4920][Time: 57.50s][Loss: 0.25531][Pearson: 0.78428][LR: 8.6592e-05]
21/01/12 14:33:18 - INFO - training -   [Ep: 10.08][Iter: 4940][Time: 12.79s][Loss: 0.24851][Pearson: 0.79065][LR: 8.6944e-05]
21/01/12 14:33:33 - INFO - training -   [Ep: 10.12][Iter: 4960][Time: 14.77s][Loss: 0.2447][Pearson: 0.79654][LR: 8.7296e-05]
21/01/12 14:33:47 - INFO - training -   [Ep: 10.16][Iter: 4980][Time: 13.43s][Loss: 0.24205][Pearson: 0.79711][LR: 8.7648e-05]
21/01/12 14:34:38 - INFO - training -   [Ep: 10.20][Iter: 5000][Time: 51.31s][Loss: 0.24428][Pearson: 0.7958][LR: 8.8e-05]
21/01/12 14:34:51 - INFO - training -   [Ep: 10.24][Iter: 5020][Time: 13.21s][Loss: 0.23762][Pearson: 0.80106][LR: 8.8352e-05]
21/01/12 14:35:04 - INFO - training -   [Ep: 10.28][Iter: 5040][Time: 13.01s][Loss: 0.2376][Pearson: 0.79869][LR: 8.8704e-05]
21/01/12 14:35:19 - INFO - training -   [Ep: 10.32][Iter: 5060][Time: 15.31s][Loss: 0.23974][Pearson: 0.79863][LR: 8.9056e-05]
21/01/12 14:35:34 - INFO - training -   [Ep: 10.37][Iter: 5080][Time: 15.12s][Loss: 0.24099][Pearson: 0.79888][LR: 8.9408e-05]
21/01/12 14:36:25 - INFO - training -   [Ep: 10.41][Iter: 5100][Time: 50.44s][Loss: 0.23853][Pearson: 0.80008][LR: 8.976e-05]
21/01/12 14:36:39 - INFO - training -   [Ep: 10.45][Iter: 5120][Time: 13.83s][Loss: 0.23469][Pearson: 0.80265][LR: 9.0112e-05]
21/01/12 14:36:54 - INFO - training -   [Ep: 10.49][Iter: 5140][Time: 14.91s][Loss: 0.23275][Pearson: 0.80523][LR: 9.0464e-05]
21/01/12 14:37:08 - INFO - training -   [Ep: 10.53][Iter: 5160][Time: 14.47s][Loss: 0.23318][Pearson: 0.80576][LR: 9.0816e-05]
21/01/12 14:37:21 - INFO - training -   [Ep: 10.57][Iter: 5180][Time: 13.33s][Loss: 0.22912][Pearson: 0.8084][LR: 9.1168e-05]
21/01/12 14:38:13 - INFO - training -   [Ep: 10.61][Iter: 5200][Time: 51.82s][Loss: 0.22836][Pearson: 0.81056][LR: 9.152e-05]
21/01/12 14:38:28 - INFO - training -   [Ep: 10.65][Iter: 5220][Time: 14.91s][Loss: 0.23017][Pearson: 0.80755][LR: 9.1872e-05]
21/01/12 14:38:42 - INFO - training -   [Ep: 10.69][Iter: 5240][Time: 14.10s][Loss: 0.22575][Pearson: 0.81051][LR: 9.2224e-05]
21/01/12 14:38:57 - INFO - training -   [Ep: 10.73][Iter: 5260][Time: 14.50s][Loss: 0.22746][Pearson: 0.8103][LR: 9.2576e-05]
21/01/12 14:39:12 - INFO - training -   [Ep: 10.77][Iter: 5280][Time: 15.12s][Loss: 0.2255][Pearson: 0.81302][LR: 9.2928e-05]
21/01/12 14:39:59 - INFO - training -   [Ep: 10.81][Iter: 5300][Time: 46.65s][Loss: 0.22534][Pearson: 0.81224][LR: 9.328e-05]
21/01/12 14:40:12 - INFO - training -   [Ep: 10.86][Iter: 5320][Time: 13.61s][Loss: 0.22115][Pearson: 0.81549][LR: 9.3632e-05]
21/01/12 14:40:27 - INFO - training -   [Ep: 10.90][Iter: 5340][Time: 14.41s][Loss: 0.22172][Pearson: 0.8153][LR: 9.3984e-05]
21/01/12 14:40:42 - INFO - training -   [Ep: 10.94][Iter: 5360][Time: 15.42s][Loss: 0.22259][Pearson: 0.81416][LR: 9.4336e-05]
21/01/12 14:40:56 - INFO - training -   [Ep: 10.98][Iter: 5380][Time: 13.82s][Loss: 0.22148][Pearson: 0.81409][LR: 9.4688e-05]
21/01/12 14:41:02 - INFO - training -   Train: [Loss: 0.23219][Pearson: 0.80582]
21/01/12 14:48:33 - INFO - training -   Evaluation: [Loss: 0.40446][Pearson: 0.73312]
21/01/12 14:48:33 - INFO - training -   ** ** * Saving trained model ** ** * 
21/01/12 14:48:34 - INFO - training -   Saving model checkpoint to outputs/single_cell_denoising_transformer_21-01-12-16-47-16_043692
21/01/12 14:49:23 - INFO - training -   [Ep: 11.02][Iter: 5400][Time: 48.49s][Loss: 0.20314][Pearson: 0.83414][LR: 9.504e-05]
21/01/12 14:49:37 - INFO - training -   [Ep: 11.06][Iter: 5420][Time: 14.43s][Loss: 0.2096][Pearson: 0.82699][LR: 9.5392e-05]
21/01/12 14:49:51 - INFO - training -   [Ep: 11.10][Iter: 5440][Time: 13.75s][Loss: 0.21216][Pearson: 0.82299][LR: 9.5744e-05]
21/01/12 14:50:06 - INFO - training -   [Ep: 11.14][Iter: 5460][Time: 14.99s][Loss: 0.21467][Pearson: 0.82161][LR: 9.6096e-05]
21/01/12 14:51:00 - INFO - training -   [Ep: 11.18][Iter: 5480][Time: 53.88s][Loss: 0.21705][Pearson: 0.82124][LR: 9.6448e-05]
21/01/12 14:51:14 - INFO - training -   [Ep: 11.22][Iter: 5500][Time: 14.05s][Loss: 0.21414][Pearson: 0.82321][LR: 9.68e-05]
21/01/12 14:51:27 - INFO - training -   [Ep: 11.26][Iter: 5520][Time: 13.56s][Loss: 0.21347][Pearson: 0.82363][LR: 9.7152e-05]
21/01/12 14:51:41 - INFO - training -   [Ep: 11.30][Iter: 5540][Time: 14.05s][Loss: 0.21094][Pearson: 0.82459][LR: 9.7504e-05]
21/01/12 14:51:57 - INFO - training -   [Ep: 11.34][Iter: 5560][Time: 15.67s][Loss: 0.21472][Pearson: 0.82159][LR: 9.7856e-05]
21/01/12 14:52:48 - INFO - training -   [Ep: 11.39][Iter: 5580][Time: 50.43s][Loss: 0.21572][Pearson: 0.82401][LR: 9.8208e-05]
21/01/12 14:53:03 - INFO - training -   [Ep: 11.43][Iter: 5600][Time: 15.54s][Loss: 0.21784][Pearson: 0.82091][LR: 9.856e-05]
21/01/12 14:53:17 - INFO - training -   [Ep: 11.47][Iter: 5620][Time: 14.29s][Loss: 0.21236][Pearson: 0.82354][LR: 9.8912e-05]
21/01/12 14:53:30 - INFO - training -   [Ep: 11.51][Iter: 5640][Time: 12.89s][Loss: 0.21065][Pearson: 0.82275][LR: 9.9264e-05]
21/01/12 14:53:43 - INFO - training -   [Ep: 11.55][Iter: 5660][Time: 13.02s][Loss: 0.20579][Pearson: 0.82731][LR: 9.9616e-05]
21/01/12 14:54:34 - INFO - training -   [Ep: 11.59][Iter: 5680][Time: 51.13s][Loss: 0.20901][Pearson: 0.82527][LR: 9.9968e-05]
21/01/12 14:54:49 - INFO - training -   [Ep: 11.63][Iter: 5700][Time: 14.15s][Loss: 0.20932][Pearson: 0.82487][LR: 0.00010032]
21/01/12 14:55:03 - INFO - training -   [Ep: 11.67][Iter: 5720][Time: 14.51s][Loss: 0.21145][Pearson: 0.82516][LR: 0.00010067]
21/01/12 14:55:18 - INFO - training -   [Ep: 11.71][Iter: 5740][Time: 15.03s][Loss: 0.21481][Pearson: 0.82363][LR: 0.00010102]
21/01/12 14:55:33 - INFO - training -   [Ep: 11.75][Iter: 5760][Time: 14.44s][Loss: 0.21015][Pearson: 0.8268][LR: 0.00010138]
21/01/12 14:56:20 - INFO - training -   [Ep: 11.79][Iter: 5780][Time: 47.38s][Loss: 0.20537][Pearson: 0.83162][LR: 0.00010173]
21/01/12 14:56:33 - INFO - training -   [Ep: 11.83][Iter: 5800][Time: 12.76s][Loss: 0.204][Pearson: 0.82954][LR: 0.00010208]
21/01/12 14:56:47 - INFO - training -   [Ep: 11.88][Iter: 5820][Time: 14.22s][Loss: 0.20307][Pearson: 0.83196][LR: 0.00010243]
21/01/12 14:57:02 - INFO - training -   [Ep: 11.92][Iter: 5840][Time: 14.97s][Loss: 0.20392][Pearson: 0.82892][LR: 0.00010278]
21/01/12 14:57:16 - INFO - training -   [Ep: 11.96][Iter: 5860][Time: 14.20s][Loss: 0.20276][Pearson: 0.8294][LR: 0.00010314]
21/01/12 14:57:30 - INFO - training -   [Ep: 12.00][Iter: 5880][Time: 13.54s][Loss: 0.20159][Pearson: 0.83118][LR: 0.00010349]
21/01/12 14:57:30 - INFO - training -   Train: [Loss: 0.21052][Pearson: 0.82529]
21/01/12 15:05:02 - INFO - training -   Evaluation: [Loss: 0.41422][Pearson: 0.73798]
21/01/12 15:05:02 - INFO - training -   ** ** * Saving trained model ** ** * 
21/01/12 15:05:03 - INFO - training -   Saving model checkpoint to outputs/single_cell_denoising_transformer_21-01-12-16-47-16_043692
21/01/12 15:05:58 - INFO - training -   [Ep: 12.04][Iter: 5900][Time: 54.72s][Loss: 0.21015][Pearson: 0.82472][LR: 0.00010384]
21/01/12 15:06:12 - INFO - training -   [Ep: 12.08][Iter: 5920][Time: 14.21s][Loss: 0.2008][Pearson: 0.83362][LR: 0.00010419]
21/01/12 15:06:27 - INFO - training -   [Ep: 12.12][Iter: 5940][Time: 14.31s][Loss: 0.20019][Pearson: 0.83403][LR: 0.00010454]
21/01/12 15:06:41 - INFO - training -   [Ep: 12.16][Iter: 5960][Time: 14.72s][Loss: 0.20094][Pearson: 0.83399][LR: 0.0001049]
21/01/12 15:07:34 - INFO - training -   [Ep: 12.20][Iter: 5980][Time: 52.51s][Loss: 0.20147][Pearson: 0.83137][LR: 0.00010525]
21/01/12 15:07:51 - INFO - training -   [Ep: 12.24][Iter: 6000][Time: 16.74s][Loss: 0.19787][Pearson: 0.83581][LR: 0.0001056]
21/01/12 15:08:06 - INFO - training -   [Ep: 12.28][Iter: 6020][Time: 15.35s][Loss: 0.20122][Pearson: 0.83396][LR: 0.00010595]
21/01/12 15:08:21 - INFO - training -   [Ep: 12.32][Iter: 6040][Time: 14.83s][Loss: 0.20025][Pearson: 0.83339][LR: 0.0001063]
21/01/12 15:08:35 - INFO - training -   [Ep: 12.37][Iter: 6060][Time: 14.40s][Loss: 0.19799][Pearson: 0.83565][LR: 0.00010666]
21/01/12 15:09:25 - INFO - training -   [Ep: 12.41][Iter: 6080][Time: 49.82s][Loss: 0.19659][Pearson: 0.83656][LR: 0.00010701]
21/01/12 15:09:39 - INFO - training -   [Ep: 12.45][Iter: 6100][Time: 13.93s][Loss: 0.19789][Pearson: 0.83664][LR: 0.00010736]
21/01/12 15:09:54 - INFO - training -   [Ep: 12.49][Iter: 6120][Time: 14.87s][Loss: 0.19536][Pearson: 0.83896][LR: 0.00010771]
21/01/12 15:10:08 - INFO - training -   [Ep: 12.53][Iter: 6140][Time: 14.50s][Loss: 0.19404][Pearson: 0.83795][LR: 0.00010806]
21/01/12 15:10:24 - INFO - training -   [Ep: 12.57][Iter: 6160][Time: 15.32s][Loss: 0.19507][Pearson: 0.83961][LR: 0.00010842]
21/01/12 15:11:16 - INFO - training -   [Ep: 12.61][Iter: 6180][Time: 52.07s][Loss: 0.19768][Pearson: 0.83564][LR: 0.00010877]
21/01/12 15:11:30 - INFO - training -   [Ep: 12.65][Iter: 6200][Time: 14.28s][Loss: 0.19729][Pearson: 0.8371][LR: 0.00010912]
21/01/12 15:11:43 - INFO - training -   [Ep: 12.69][Iter: 6220][Time: 12.81s][Loss: 0.19755][Pearson: 0.83475][LR: 0.00010947]
21/01/12 15:11:57 - INFO - training -   [Ep: 12.73][Iter: 6240][Time: 13.80s][Loss: 0.19371][Pearson: 0.8387][LR: 0.00010982]
21/01/12 15:12:10 - INFO - training -   [Ep: 12.77][Iter: 6260][Time: 13.44s][Loss: 0.19625][Pearson: 0.8383][LR: 0.00011018]
21/01/12 15:12:57 - INFO - training -   [Ep: 12.81][Iter: 6280][Time: 46.51s][Loss: 0.19458][Pearson: 0.83953][LR: 0.00011053]
21/01/12 15:13:11 - INFO - training -   [Ep: 12.86][Iter: 6300][Time: 14.03s][Loss: 0.19295][Pearson: 0.83993][LR: 0.00011088]
21/01/12 15:13:25 - INFO - training -   [Ep: 12.90][Iter: 6320][Time: 14.19s][Loss: 0.19291][Pearson: 0.83995][LR: 0.00011123]
21/01/12 15:13:39 - INFO - training -   [Ep: 12.94][Iter: 6340][Time: 14.76s][Loss: 0.19267][Pearson: 0.84152][LR: 0.00011158]
21/01/12 15:13:52 - INFO - training -   [Ep: 12.98][Iter: 6360][Time: 12.80s][Loss: 0.19135][Pearson: 0.84095][LR: 0.00011194]
21/01/12 15:14:00 - INFO - training -   Train: [Loss: 0.19666][Pearson: 0.83704]
21/01/12 15:21:31 - INFO - training -   Evaluation: [Loss: 0.47286][Pearson: 0.73459]
21/01/12 15:21:31 - INFO - training -   ** ** * Saving trained model ** ** * 
21/01/12 15:21:32 - INFO - training -   Saving model checkpoint to outputs/single_cell_denoising_transformer_21-01-12-16-47-16_043692
21/01/12 15:22:23 - INFO - training -   [Ep: 13.02][Iter: 6380][Time: 50.89s][Loss: 0.19044][Pearson: 0.83354][LR: 0.00011229]
21/01/12 15:22:36 - INFO - training -   [Ep: 13.06][Iter: 6400][Time: 12.85s][Loss: 0.18931][Pearson: 0.84161][LR: 0.00011264]
21/01/12 15:22:50 - INFO - training -   [Ep: 13.10][Iter: 6420][Time: 14.56s][Loss: 0.19156][Pearson: 0.84134][LR: 0.00011299]
21/01/12 15:23:05 - INFO - training -   [Ep: 13.14][Iter: 6440][Time: 14.75s][Loss: 0.19119][Pearson: 0.84181][LR: 0.00011334]
21/01/12 15:23:57 - INFO - training -   [Ep: 13.18][Iter: 6460][Time: 52.14s][Loss: 0.1932][Pearson: 0.84094][LR: 0.0001137]
21/01/12 15:24:10 - INFO - training -   [Ep: 13.22][Iter: 6480][Time: 13.14s][Loss: 0.19205][Pearson: 0.84051][LR: 0.00011405]
21/01/12 15:24:25 - INFO - training -   [Ep: 13.26][Iter: 6500][Time: 14.99s][Loss: 0.19092][Pearson: 0.84191][LR: 0.0001144]
21/01/12 15:24:39 - INFO - training -   [Ep: 13.30][Iter: 6520][Time: 14.35s][Loss: 0.19102][Pearson: 0.84195][LR: 0.00011475]
21/01/12 15:24:54 - INFO - training -   [Ep: 13.34][Iter: 6540][Time: 15.00s][Loss: 0.1902][Pearson: 0.84234][LR: 0.0001151]
21/01/12 15:25:45 - INFO - training -   [Ep: 13.39][Iter: 6560][Time: 50.20s][Loss: 0.19145][Pearson: 0.84063][LR: 0.00011546]
21/01/12 15:25:58 - INFO - training -   [Ep: 13.43][Iter: 6580][Time: 13.77s][Loss: 0.18933][Pearson: 0.84321][LR: 0.00011581]
21/01/12 15:26:12 - INFO - training -   [Ep: 13.47][Iter: 6600][Time: 13.45s][Loss: 0.18724][Pearson: 0.84568][LR: 0.00011616]
21/01/12 15:26:26 - INFO - training -   [Ep: 13.51][Iter: 6620][Time: 14.59s][Loss: 0.18721][Pearson: 0.84585][LR: 0.00011651]
21/01/12 15:26:40 - INFO - training -   [Ep: 13.55][Iter: 6640][Time: 13.95s][Loss: 0.18802][Pearson: 0.84476][LR: 0.00011686]
21/01/12 15:27:31 - INFO - training -   [Ep: 13.59][Iter: 6660][Time: 50.61s][Loss: 0.18944][Pearson: 0.84449][LR: 0.00011722]
21/01/12 15:27:47 - INFO - training -   [Ep: 13.63][Iter: 6680][Time: 16.47s][Loss: 0.18675][Pearson: 0.84621][LR: 0.00011757]
21/01/12 15:28:04 - INFO - training -   [Ep: 13.67][Iter: 6700][Time: 16.23s][Loss: 0.18863][Pearson: 0.84401][LR: 0.00011792]
21/01/12 15:28:18 - INFO - training -   [Ep: 13.71][Iter: 6720][Time: 14.22s][Loss: 0.18706][Pearson: 0.84536][LR: 0.00011827]
21/01/12 15:28:31 - INFO - training -   [Ep: 13.75][Iter: 6740][Time: 13.29s][Loss: 0.18573][Pearson: 0.84579][LR: 0.00011862]
21/01/12 15:29:19 - INFO - training -   [Ep: 13.79][Iter: 6760][Time: 47.44s][Loss: 0.18645][Pearson: 0.84572][LR: 0.00011898]
21/01/12 15:29:32 - INFO - training -   [Ep: 13.83][Iter: 6780][Time: 13.62s][Loss: 0.18492][Pearson: 0.84739][LR: 0.00011933]
21/01/12 15:29:46 - INFO - training -   [Ep: 13.88][Iter: 6800][Time: 13.94s][Loss: 0.18423][Pearson: 0.84848][LR: 0.00011968]
21/01/12 15:30:00 - INFO - training -   [Ep: 13.92][Iter: 6820][Time: 14.14s][Loss: 0.18406][Pearson: 0.84829][LR: 0.00012003]
21/01/12 15:30:18 - INFO - training -   [Ep: 13.96][Iter: 6840][Time: 17.78s][Loss: 0.1846][Pearson: 0.84839][LR: 0.00012038]
21/01/12 15:30:32 - INFO - training -   [Ep: 14.00][Iter: 6860][Time: 13.72s][Loss: 0.18343][Pearson: 0.84806][LR: 0.00012074]
21/01/12 15:30:32 - INFO - training -   Train: [Loss: 0.18825][Pearson: 0.84452]
21/01/12 15:38:03 - INFO - training -   Evaluation: [Loss: 0.44771][Pearson: 0.73836]
21/01/12 15:38:03 - INFO - training -   ** ** * Saving trained model ** ** * 
21/01/12 15:38:04 - INFO - training -   Saving model checkpoint to outputs/single_cell_denoising_transformer_21-01-12-16-47-16_043692
21/01/12 15:39:00 - INFO - training -   [Ep: 14.04][Iter: 6880][Time: 56.54s][Loss: 0.1857][Pearson: 0.84154][LR: 0.00012109]
21/01/12 15:39:13 - INFO - training -   [Ep: 14.08][Iter: 6900][Time: 13.15s][Loss: 0.1891][Pearson: 0.84294][LR: 0.00012144]
21/01/12 15:39:28 - INFO - training -   [Ep: 14.12][Iter: 6920][Time: 14.63s][Loss: 0.1831][Pearson: 0.85051][LR: 0.00012179]
21/01/12 15:39:42 - INFO - training -   [Ep: 14.16][Iter: 6940][Time: 13.86s][Loss: 0.18182][Pearson: 0.85035][LR: 0.00012214]
21/01/12 15:40:33 - INFO - training -   [Ep: 14.20][Iter: 6960][Time: 51.23s][Loss: 0.1837][Pearson: 0.84929][LR: 0.0001225]
21/01/12 15:40:47 - INFO - training -   [Ep: 14.24][Iter: 6980][Time: 13.80s][Loss: 0.18595][Pearson: 0.84873][LR: 0.00012285]
21/01/12 15:40:59 - INFO - training -   [Ep: 14.28][Iter: 7000][Time: 12.43s][Loss: 0.19297][Pearson: 0.84558][LR: 0.0001232]
21/01/12 15:41:14 - INFO - training -   [Ep: 14.32][Iter: 7020][Time: 15.13s][Loss: 0.1955][Pearson: 0.84537][LR: 0.00012355]
21/01/12 15:41:30 - INFO - training -   [Ep: 14.37][Iter: 7040][Time: 15.53s][Loss: 0.18854][Pearson: 0.84849][LR: 0.0001239]
21/01/12 15:42:21 - INFO - training -   [Ep: 14.41][Iter: 7060][Time: 51.17s][Loss: 0.18448][Pearson: 0.84881][LR: 0.00012426]
21/01/12 15:42:34 - INFO - training -   [Ep: 14.45][Iter: 7080][Time: 13.21s][Loss: 0.18352][Pearson: 0.84915][LR: 0.00012461]
21/01/12 15:42:50 - INFO - training -   [Ep: 14.49][Iter: 7100][Time: 15.35s][Loss: 0.18592][Pearson: 0.84721][LR: 0.00012496]
21/01/12 15:43:05 - INFO - training -   [Ep: 14.53][Iter: 7120][Time: 15.50s][Loss: 0.18261][Pearson: 0.85025][LR: 0.00012531]
21/01/12 15:43:18 - INFO - training -   [Ep: 14.57][Iter: 7140][Time: 12.63s][Loss: 0.17985][Pearson: 0.85006][LR: 0.00012566]
21/01/12 15:44:08 - INFO - training -   [Ep: 14.61][Iter: 7160][Time: 50.80s][Loss: 0.18041][Pearson: 0.85102][LR: 0.00012602]
21/01/12 15:44:24 - INFO - training -   [Ep: 14.65][Iter: 7180][Time: 15.21s][Loss: 0.18132][Pearson: 0.85056][LR: 0.00012637]
21/01/12 15:44:38 - INFO - training -   [Ep: 14.69][Iter: 7200][Time: 13.99s][Loss: 0.17946][Pearson: 0.85101][LR: 0.00012672]
21/01/12 15:44:51 - INFO - training -   [Ep: 14.73][Iter: 7220][Time: 13.30s][Loss: 0.18019][Pearson: 0.8516][LR: 0.00012707]
21/01/12 15:45:06 - INFO - training -   [Ep: 14.77][Iter: 7240][Time: 14.59s][Loss: 0.17779][Pearson: 0.85349][LR: 0.00012742]
21/01/12 15:45:52 - INFO - training -   [Ep: 14.81][Iter: 7260][Time: 46.82s][Loss: 0.1777][Pearson: 0.85318][LR: 0.00012778]
21/01/12 15:46:08 - INFO - training -   [Ep: 14.86][Iter: 7280][Time: 15.64s][Loss: 0.17914][Pearson: 0.85211][LR: 0.00012813]
21/01/12 15:46:23 - INFO - training -   [Ep: 14.90][Iter: 7300][Time: 14.50s][Loss: 0.18208][Pearson: 0.84869][LR: 0.00012848]
21/01/12 15:46:36 - INFO - training -   [Ep: 14.94][Iter: 7320][Time: 12.99s][Loss: 0.18027][Pearson: 0.8523][LR: 0.00012883]
21/01/12 15:46:50 - INFO - training -   [Ep: 14.98][Iter: 7340][Time: 14.44s][Loss: 0.1816][Pearson: 0.85051][LR: 0.00012918]
21/01/12 15:46:57 - INFO - training -   Train: [Loss: 0.18331][Pearson: 0.84976]
21/01/12 15:54:29 - INFO - training -   Evaluation: [Loss: 0.44393][Pearson: 0.74099]
21/01/12 15:54:29 - INFO - training -   ** ** * Saving trained model ** ** * 
21/01/12 15:54:30 - INFO - training -   Saving model checkpoint to outputs/single_cell_denoising_transformer_21-01-12-16-47-16_043692
21/01/12 15:54:30 - INFO - training -   Finished training at epoch 14 because no improvement for 6 epochs.
21/01/12 15:54:30 - Level 35 - training -   Best Val Loss: 0.2900811120661722
21/01/12 15:54:30 - INFO - training -   Finished training after 100 epochs.
21/01/12 15:54:30 - Level 35 - training -   Best Val Loss: 0.2900811120661722
